{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "ef813660",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import cv2\n",
    "import random\n",
    "import pickle\n",
    "from tqdm import tqdm\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier \n",
    "from sklearn.linear_model import LogisticRegression \n",
    "from sklearn.naive_bayes import MultinomialNB \n",
    "from sklearn.tree import DecisionTreeClassifier \n",
    "from sklearn.svm import SVC \n",
    "from sklearn.neural_network import MLPClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "d6847f2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_DIRECTORY = r'C:\\Users\\daniela\\OneDrive\\Documents\\geral\\pibic\\digits'\n",
    "LABELS = []\n",
    "IMG_SIZE = 28\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "779f28f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['0', '1', '2', '3', '4', '5', '6', '7', '8', '9']\n"
     ]
    }
   ],
   "source": [
    "# ARRAY DE LABELS BASEADO NO NOME DAS PASTAS\n",
    "for dir_name in range(len(os.listdir(DATASET_DIRECTORY))):\n",
    "    LABELS.append(os.listdir(DATASET_DIRECTORY)[dir_name])\n",
    "\n",
    "print(LABELS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "fe577646",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6903/6903 [00:01<00:00, 5947.19it/s]\n",
      "100%|██████████| 7877/7877 [00:01<00:00, 6064.04it/s]\n",
      "100%|██████████| 6990/6990 [00:01<00:00, 5798.41it/s]\n",
      "100%|██████████| 7141/7141 [00:01<00:00, 5296.64it/s]\n",
      "100%|██████████| 6824/6824 [00:01<00:00, 6343.87it/s]\n",
      "100%|██████████| 6313/6313 [00:01<00:00, 6270.63it/s]\n",
      "100%|██████████| 6876/6876 [00:01<00:00, 5809.82it/s]\n",
      "100%|██████████| 7293/7293 [00:01<00:00, 5993.09it/s]\n",
      "100%|██████████| 6825/6825 [00:01<00:00, 5760.18it/s]\n",
      "100%|██████████| 6958/6958 [00:01<00:00, 5953.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "70000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "training_data = []\n",
    "\n",
    "def create_training_data():\n",
    "    for category in LABELS\n",
    "\n",
    "        path = os.path.join(DATADIR,category)\n",
    "        class_num = LABELS.index(category)\n",
    "\n",
    "        for img in tqdm(os.listdir(path)):\n",
    "            try:\n",
    "                img_array = cv2.imread(os.path.join(path,img) ,cv2.IMREAD_GRAYSCALE)\n",
    "                new_array = cv2.resize(img_array, (IMG_SIZE, IMG_SIZE))\n",
    "                training_data.append([new_array, class_num])\n",
    "            except Exception as e:\n",
    "                print(\"erro\")\n",
    "                pass\n",
    "            #except OSError as e:\n",
    "            #    print(\"OSErrroBad img most likely\", e, os.path.join(path,img))\n",
    "            #except Exception as e:\n",
    "            #    print(\"general exception\", e, os.path.join(path,img))\n",
    "\n",
    "create_training_data()\n",
    "\n",
    "print(len(training_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "f49a85a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SEPARANDO IMG E LABEL\n",
    "\n",
    "x = []\n",
    "y = []\n",
    "\n",
    "for features, label in training_data:\n",
    "    x.append(features)\n",
    "    y.append(label)\n",
    "\n",
    "# print(x[0].reshape(-1, IMG_SIZE, IMG_SIZE, 1))\n",
    "\n",
    "x = np.array(x).reshape(-1, IMG_SIZE, IMG_SIZE, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "2a16ee46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SALVAR DATASET\n",
    "\n",
    "pickle_out = open('x.pickle', 'wb')\n",
    "pickle.dump(x, pickle_out)\n",
    "pickle_out.close()\n",
    "\n",
    "pickle_out = open('y.pickle', 'wb')\n",
    "pickle.dump(y, pickle_out)\n",
    "pickle_out.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "ffa51f24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CARREGAR DATASET\n",
    "\n",
    "pickle_in = open('x.pickle', 'rb')\n",
    "x = pickle.load(pickle_in)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b3e7e73",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
